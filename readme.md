# åŸºäºHiveçš„ç”¨æˆ·è¡Œä¸ºåˆ†æç³»ç»Ÿ
## âš¡æ ¸å¿ƒæŠ€æœ¯æ ˆ

- â˜•**Java-1.8** :æœ€å—æ¬¢è¿çš„ä¸€ä¸ªç‰ˆæœ¬ã€‚
- ğŸ¦“**Hive-3.1** ï¼š  åœ¨3.xä¹‹å‰ä¹Ÿæ”¯æŒ`update`,ä½†æ˜¯é€Ÿåº¦å¤ªæ…¢ï¼Œè¿˜éœ€è¦è¿›è¡Œåˆ†æ¡¶ï¼Œç°åœ¨`Hive` æ”¯æŒå…¨æ–°`ACID`ï¼Œå¹¶ä¸”åº•å±‚é‡‡ç”¨`TEZå¼•æ“` å’Œå†…å­˜è¿›è¡ŒæŸ¥è¯¢ï¼Œæ¯”`Hive-2.*`æé«˜2-50å€ã€‚
  `Apache Tez`å°†`MapReduce`æ›¿æ¢ä¸ºé»˜è®¤çš„`Hive`æ‰§è¡Œå¼•æ“ã€‚ä¸å†æ”¯æŒ`MapReduce`ï¼Œå¹¶è¯æ˜äº†`Tez`çš„ç¨³å®šæ€§ã€‚é€šè¿‡æœ‰å‘æ— ç¯å›¾ï¼ˆDAGï¼‰å’Œæ•°æ®ä¼ è¾“åŸè¯­çš„è¡¨è¾¾å¼ï¼Œåœ¨`Tez`ä¸‹æ‰§è¡Œ`Hive`æŸ¥è¯¢å¯ä»¥æé«˜æ€§èƒ½ã€‚ 
- ğŸ˜**Hadoop-3.2.0**: `Hadoop3.x`ä»¥åå°†ä¼šè°ƒæ•´æ–¹æ¡ˆæ¶æ„ï¼Œå°†`Mapreduce` åŸºäºå†…å­˜+io+ç£ç›˜ï¼Œå…±åŒå¤„ç†æ•°æ®ã€‚
  å…¶å®æœ€å¤§æ”¹å˜çš„æ˜¯`HDFS`,`HDFS`é€šè¿‡æœ€è¿‘`black`å—è®¡ç®—ï¼Œæ ¹æ®æœ€è¿‘è®¡ç®—åŸåˆ™ï¼Œæœ¬åœ°`black`å—ï¼ŒåŠ å…¥åˆ°å†…å­˜ï¼Œå…ˆè®¡ç®—ï¼Œé€šè¿‡IOï¼Œå…±äº«å†…å­˜è®¡ç®—åŒºåŸŸï¼Œæœ€åå¿«é€Ÿå½¢æˆè®¡ç®—ç»“æœã€‚ 
- â˜•ğŸ”—ğŸ¦“**HiveJDBC:** é€šè¿‡`Java`ç›´æ¥è®¿é—®`Hive`æ•°æ®åº“ 
- ğŸ˜ğŸ”—ğŸ¦“**HiveServer2**:ä½¿è¿œç¨‹å®¢æˆ·ç«¯å¯ä»¥æ‰§è¡Œå¯¹`Hive`çš„æŸ¥è¯¢å¹¶è¿”å›ç»“æœ 
- ...
hadoop jar mr-project-1.0-SNAPSHOT.jar com.nuc.MRDriver /opt/software/å­¦ç”Ÿè€ƒè¯•ä¿¡æ¯-å¤„ç†.csv /opt/moudle/hadoop/output/exam


## å¯åŠ¨æœåŠ¡æ‰€éœ€ç»„ä»¶
æœåŠ¡å™¨ + hadoop 3.1.3 hive 3.1.2 mysql8.0+ tmux
å¯åŠ¨æ­¥éª¤ï¼š
1. å¯åŠ¨å‰å…³é—­é˜²ç«å¢™ systemctl stop firewalld æˆ–è€… service firewalld stop  è®°ä½è¦æ‰“å¼€å®‰å…¨ç»„
2. å¯åŠ¨hadoopæœåŠ¡ å» hadoopç›®å½•ä¸‹ ./sbin/start-all.sh
3. å¯åŠ¨hiveæœåŠ¡ å»hiveç›®å½•ä¸‹  ./bin/hiveserver2  æŸ¥çœ‹10000ç«¯å£ï¼š sudo lsof -nP -iTCP:10000 -sTCP:LISTEN
4. å†™æ¥å£æµ‹è¯•å°±è¡Œäº†
## é¡¹ç›®ä»‹ç»åŠæ„æˆ
> é¡¹ç›®ä¸»è¦ç”± é¡¹ç›®ä¸Šä¼  æ•°æ®çš„é¢„å¤„ç† æ•°æ®çš„å¤„ç† æ•°æ®çš„æ˜¾ç¤º å››éƒ¨åˆ†ç»„æˆ
### é¡¹ç›®ä¸Šä¼ 
åŸºäºHDFSçš„ä¸Šä¼ ï¼Œå®ç°å¯¹æ•°æ®çš„æ˜¾ç¤ºï¼Œä¸Šä¼ ï¼Œåˆ é™¤ï¼Œä»¥åŠåˆ›å»ºï¼Œæœ¬éƒ¨åˆ†å¯è§†åŒ–ä¸Šä¼ 

### æ•°æ®çš„é¢„å¤„ç†
ç”±äºCSVä¸­æ•°æ®é‡Œå­˜åœ¨å¾ˆå¤§çš„é—®é¢˜ï¼Œæ¯”å¦‚æ•°æ®ä¸­æœ‰ç©ºè¡Œæˆ–è€…æ˜¯å›è½¦ï¼Œå¯¼è‡´MapReduceå¤„ç†æ—¶ä¸èƒ½å¤„ç†ä¸€è¡Œï¼Œå› æ­¤è¿™é‡Œä½¿ç”¨äº†ç”¨Pythonå¤„ç†æ•°æ®ï¼Œç„¶åå†ç”¨MapReduceè¿›è¡Œå¤„ç†

timetamp è½¬ä¸º date ï¼šselect from_unixtime(unix_timestamp(dt),'yyyy-MM-dd') from test;
select from_unixtime(unix_timestamp(dt),'yyyy-MM-dd'),count(distinct from_unixtime(unix_timestamp(dt),'yyyy-MM-dd')) from

select from_unixtime(unix_timestamp(ruleTime),'yyyy-MM-dd'),count(from_unixtime(unix_timestamp(ruleTime),'yyyy-MM-dd')) as count from daily group by ruleTime ;

### æ•°æ®çš„å¤„ç†
ä½¿ç”¨HiveSQLè¿›è¡Œå¤„ç†ï¼Œè®¾è®¡åˆ°æ¯”è¾ƒå¤æ‚çš„SQLè¯­å¥
```sql
åˆ›å»ºæ•°æ®åº“:
create databse nuc;
use nuc;

create table daily(
    id string,
    studentNo int,
    classNo int,
    ruleTime timestamp,
    motto string,
    workContent string,
    completion double,
    note string,
    addTime timestamp,
    isDaily int                                                        
)
ROW FORMAT DELIMITED FIELDS TERMINATED BY  ','
STORED AS TEXTFILE;
create table exam(
    paperNo string,
    studentNo int,
    subjectiveScore double,
    objectiveScore double,
    score double,
    isRead int,
    isSubmit int,
    isEnter int,
    subjectiveDetails string,
    objectiveDetails string
)
ROW FORMAT DELIMITED FIELDS TERMINATED BY  ','
STORED AS TEXTFILE;

åŠ è½½hdfsæ•°æ®è¿›hiveæ•°æ®åº“ï¼š
load data inpath '/opt/moudle/hadoop/output/daily/part-r-00000' into table daily;
load data inpath '/opt/moudle/hadoop/output/exam/part-r-00000' into table exam;
æŸ¥çœ‹è¡¨ç»“æ„ï¼š
desc daily;
è¡¨çš„è¯¦ç»†å±æ€§ï¼š
desc formatted daily
æŸ¥çœ‹è¡¨æ‰€åœ¨è·¯å¾„ï¼š
describe extended daily
æŸ¥çœ‹éƒ¨åˆ†å†…å®¹ï¼š
select * from daily limit 10;
select * from exam limit 10;
åˆ é™¤è¡¨ï¼š
drop table daily;



```

### æ•°æ®çš„æ˜¾ç¤º
```sql
æ˜¾ç¤ºè¦æ±‚ï¼šç³»ç»Ÿä¸»è¦å®ç°é€šè¿‡å¯¹ä¼˜é€¸å®¢å®è®­å¹³å°çš„ç”¨æˆ·è®¿é—®æ•°æ®è¿›è¡Œç»Ÿè®¡åˆ†æï¼Œ
å®ç°ç»Ÿè®¡åˆ†ææ¯æ—¥è®¿é—®é‡ã€
INSERT INTO TABLE  Time_count 
select from_unixtime(unix_timestamp(ruleTime),'yyyy-MM-dd'),count(from_unixtime(unix_timestamp(ruleTime),'yyyy-MM-dd')) as count from daily group by ruleTime ;
æ—¥æŠ¥åŠŸèƒ½çš„æ¯æ—¥é«˜å³°æœŸ
create table case2(hour int, count int)STORED AS TEXTFILE;
insert into table case2 select from_unixtime(unix_timestamp(addTime),'HH'),count(from_unixtime(unix_timestamp(addTime),'HH')) as count from daily group by addTime ;
create table case22(hour int, count int)STORED AS TEXTFILE;
insert into table case22 select hour, count(count) from case2 group by id ;
select hour,count from case22 where count = (select max(count) from case22);
æ—¥æŠ¥æ¯æ—¥æäº¤æ•°é‡ã€
create table case2(hour int, count int)STORED AS TEXTFILE;
insert into table case2 select from_unixtime(unix_timestamp(addTime),'HH'),count(from_unixtime(unix_timestamp(addTime),'HH')) as count from daily group by addTime ;
select hour, count(count) from case2 group by hour;
å­¦å‘˜è€ƒè¯•å¹³å‡æ—¶é•¿ã€

å­¦å‘˜è€ƒè¯•é«˜å³°æœŸç­‰åŠŸèƒ½
å‘¨æŠ¥ä¸æ—¥æŠ¥æ¯”ä¾‹ï¼š
select count(isdaily) from daily where isdaily = 0;
select count(isdaily) from daily where isdaily = 1;
select count(isdaily) from exam 
å®Œæˆç‡ä¸º100æœ€å¤šçš„äº”ä½å­¦ç”Ÿï¼š
 select studentno ,count(completion) as cnt from daily where completion = 100 group by studentno order by cnt desc limit 5;
æäº¤æ—¥æŠ¥æ¬¡æ•°æœ€å¤šçš„ç­çº§ï¼š
select classno ,count(classno) as cnt from daily where isdaily = 0 group by classno order by cnt desc limit 5;
æäº¤å‘¨æŠ¥æ¬¡æ•°æœ€å¤šçš„ç­çº§ï¼š
select classno ,count(classno) as cnt from daily where isdaily = 1 group by classno order by cnt desc limit 5;
æ ¼è¨€ç²¾ç‚¼çš„äº”ä½åŒå­¦çš„æ ¼è¨€ï¼š
 select studentno ,motto from daily where length(motto) = 5 limit 5;


å‚åŠ è€ƒè¯•ä¸æœªå‚åŠ è€ƒè¯•æ¯”ä¾‹
select count(issubmit) from exam where issubmit = 0;
select count(issubmit) from exam where issubmit = 1;
select count(issubmit) from exam 


ï¼ˆå¯åœ¨å®ŒæˆåŸºç¡€åŠŸèƒ½ä¸Šè‡ªç”±æ‰©å±•æ–°åŠŸèƒ½ï¼‰ï¼Œæ ¹æ®ä»¥ä¸ŠåŠŸèƒ½å®ç°ç›¸å…³æ•°æ®å¯è§†åŒ–å±•ç¤ºã€‚
å°†å¤„ç†å®Œçš„JSONæ•°æ®è¿›è¡Œå›æ˜¾ï¼Œæ˜¾ç¤ºåˆ°æ•°æ®å¯è§†åŒ–å¤§å±ä¸Š

ä¸»è§‚æˆç»©å‰äº”ï¼šselect studentno from exam order by subjectivescore desc limit 5;
å®¢è§‚æˆç»©å‰äº”ï¼šselect studentno from exam order by objectivescore desc limit 5;
æ€»æˆç»©å‰äº”ï¼šselect studentno from exam order by score desc limit 5;
å‚åŠ è€ƒè¯•æ¬¡æ•°æœ€å¤šçš„äº”ä½ï¼š
select studentno ,count(studentno) as cnt from exam where issubmit != 0 group by studentno order by cnt desc limit 5;
å‚åŠ è€ƒè¯•äººæœ€å¤šçš„å‰äº”åœºè€ƒè¯•ï¼š
select paperno ,count(paperno) as cnt from exam group by paperno order by cnt desc limit 5;

```

## æ ¸å¿ƒä»£ç å±•ç¤ºï¼š
hive-site.xml
```xml
  1 <?xml version="1.0" encoding="UTF-8" standalone="no"?>
  2 <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
  3 <configuration>
  4   <property>
  5     <name>javax.jdo.option.ConnectionURL</name>
  6     <value>jdbc:mysql://localhost:3306/hive?createDatabaseIfNotExist=true</value>
  7     <description>JDBC connect string for a JDBC metastore</description>
  8   </property>
  9   <property>
 10     <name>javax.jdo.option.ConnectionDriverName</name>
 11     <value>com.mysql.cj.jdbc.Driver</value>
 12     <description>Driver class name for a JDBC metastore</description>
 13   </property>
 14   <property>
 15     <name>javax.jdo.option.ConnectionUserName</name>
 16     <value>hive</value>
 17     <description>username to use against metastore database</description>
 18   </property>
 19   <property>
 20     <name>javax.jdo.option.ConnectionPassword</name>
 21     <value>123456</value>
 22     <description>password to use against metastore database</description>
 23   </property>
 24 </configuration>

```
core-site.xml
```xml

<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License. See accompanying LICENSE file.
-->

<!-- Put site-specific property overrides in this file. -->
<configuration>
    <property>
        <name>hadoop.tmp.dir</name>
        <value>file:/opt/moudle/hadoop-3.1.3/tmp</value>
        <description>Abase for other temporary directories.</description>
    </property>
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://hadoop-master:9000</value>
    </property>
    <property>
         <name>dfs.permissions</name>
         <value>false</value>
     </property>

     <property>
         <name>hadoop.proxyuser.root.hosts</name>
         <value>*</value>
     </property>
     <property>
         <name>hadoop.proxyuser.root.groups</name>
         <value>*</value>
     </property>

</configuration>

```
hdfs-site.xml
```xml
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License. See accompanying LICENSE file.
-->

<!-- Put site-specific property overrides in this file. -->
<configuration>
    <property>
        <name>dfs.replication</name>
        <value>1</value>
    </property>
    <property>
        <name>dfs.namenode.name.dir</name>
        <value>file:/opt/moudle/hadoop-3.1.3/tmp/dfs/name</value>
    </property>
    <property>
        <name>dfs.datanode.data.dir</name>
        <value>file:/opt/moudle/hadoop-3.1.3/tmp/dfs/data</value>
    </property>

    <property>
        <name>dfs.webhdfs.enabled</name>
        <value>true</value>
    </property>
----
</configuration>

```
yarn-site.xml
```xml
<?xml version="1.0"?>
<!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License. See accompanying LICENSE file.
-->
<configuration>

<!-- Site specific YARN configuration properties -->
    <property>
        <name>mapred.job.tracker</name>
        <value>localhost:9001</value>
    </property>
</configuration>

```

## é‡åˆ°çš„BUG
1. é‡åˆ°Hive JDBC:java.lang.RuntimeException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.securi...
è§£å†³æ–¹æ¡ˆï¼šå¦‚ä¸Šä»£ç ï¼šcore-site.xmlä¸hdfs-siteä¸­æ·»åŠ éƒ¨åˆ†ä»£ç å³å¯



